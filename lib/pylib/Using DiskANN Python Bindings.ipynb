{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69f51cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diskann import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c360968",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import ftplib\n",
    "import tarfile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1a2d0b",
   "metadata": {},
   "source": [
    "## Sample Data\n",
    "- The SIFTSMALL dataset(ftp://ftp.irisa.fr/local/texmex/corpus/siftsmall.tar.gz) contains 10,000 vectors with dimensions=128\n",
    "- These vectors are used to create the index\n",
    "- The same vectors are used to perform search as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17912a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ftplib\n",
    "FILENAME = \"siftsmall.tar.gz\"\n",
    "\n",
    "ftp_url = \"ftp.irisa.fr\"\n",
    "with ftplib.FTP(ftp_url) as ftp:\n",
    "    ftp.login()\n",
    "    ftp.cwd(\"local/texmex/corpus\")\n",
    "    with open(\"/tmp/siftsmall.tar.gz\", 'wb') as f:\n",
    "        ftp.retrbinary('RETR ' + FILENAME, f.write)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24185f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = tarfile.open('/tmp/siftsmall.tar.gz')\n",
    "# extracting file\n",
    "file.extractall('/tmp')\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ef3d7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fvecs_read(filename, c_contiguous=True):\n",
    "    fv = np.fromfile(filename, dtype=np.float32)\n",
    "    if fv.size == 0:\n",
    "        return np.zeros((0, 0))\n",
    "    dim = fv.view(np.int32)[0]\n",
    "    assert dim > 0\n",
    "    fv = fv.reshape(-1, 1 + dim)\n",
    "    if not all(fv.view(np.int32)[:, 0] == dim):\n",
    "        raise IOError(\"Non-uniform vector sizes in \" + filename)\n",
    "    fv = fv[:, 1:]\n",
    "    if c_contiguous:\n",
    "        fv = fv.copy()\n",
    "    return fv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49a1b417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "siftsmall_base.fvecs        siftsmall_learn.fvecs\r\n",
      "siftsmall_groundtruth.ivecs siftsmall_query.fvecs\r\n"
     ]
    }
   ],
   "source": [
    "! ls /tmp/siftsmall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6194161",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/tmp/siftsmall\"\n",
    "vecs_file = os.path.join(path, \"siftsmall_base.fvecs\")\n",
    "np_sift = fvecs_read(vecs_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e9c68c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d91b10b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting index build: R=32 L=50 Query RAM budget: 3.22123e+08 Indexing ram budget: 1 T: 32\n",
      "Compressing 128-dimensional data into 128 bytes per vector.\n",
      "Opened: /var/folders/hd/8ct1rg6n3w71kzr3lkhz1ffh0000gn/T/tmpnx6rqi70, size: 5120008, cache_size: 5120008\n",
      "Training data loaded of size 10000\n",
      " Stat(./DiskANN_data/siftsmall_pq_pivots.bin) returned: 0\n",
      "Reading bin file ./DiskANN_data/siftsmall_pq_pivots.bin ...\n",
      "Metadata: #pts = 256, #dims = 128...\n",
      "PQ pivot file exists. Not generating again\n",
      "Opened: /var/folders/hd/8ct1rg6n3w71kzr3lkhz1ffh0000gn/T/tmpnx6rqi70, size: 5120008, cache_size: 5120008\n",
      " Stat(./DiskANN_data/siftsmall_pq_pivots.bin) returned: 0\n",
      "Reading bin file ./DiskANN_data/siftsmall_pq_pivots.bin_centroid.bin ...\n",
      "Metadata: #pts = 128, #dims = 1...\n",
      "Reading bin file ./DiskANN_data/siftsmall_pq_pivots.bin_rearrangement_perm.bin ...\n",
      "Metadata: #pts = 128, #dims = 1...\n",
      "Reading bin file ./DiskANN_data/siftsmall_pq_pivots.bin_chunk_offsets.bin ...\n",
      "Metadata: #pts = 129, #dims = 1...\n",
      "Reading bin file ./DiskANN_data/siftsmall_pq_pivots.bin ...\n",
      "Metadata: #pts = 256, #dims = 128...\n",
      "Loaded PQ pivot information\n",
      "Processing points  [0, 10000)...done.\n",
      "Full index fits in RAM budget, should consume at most 0.00821352GiBs, so building in one shot\n",
      "Number of frozen points = 0\n",
      "Reading bin file /var/folders/hd/8ct1rg6n3w71kzr3lkhz1ffh0000gn/T/tmpnx6rqi70 ...Metadata: #pts = 10000, #dims = 128, aligned_dim = 128...allocating aligned memory, 5120000 bytes...done. Copying data... done.\n",
      "Using AVX2 distance computation\n",
      "Starting index build...\n",
      "Number of syncs: 40\n",
      "Completed  (round: 0, sync: 1/40 with L 50) sync_time: 0.01407s; inter_time: 0.003209s\n",
      "Completed  (round: 0, sync: 3/40 with L 50) sync_time: 0.02736s; inter_time: 0.001461s\n",
      "Completed  (round: 0, sync: 5/40 with L 50) sync_time: 0.02829s; inter_time: 0.0008374s\n",
      "Completed  (round: 0, sync: 7/40 with L 50) sync_time: 0.02879s; inter_time: 0.001128s\n",
      "Completed  (round: 0, sync: 9/40 with L 50) sync_time: 0.03045s; inter_time: 0.001088s\n",
      "Completed  (round: 0, sync: 11/40 with L 50) sync_time: 0.03262s; inter_time: 0.001751s\n",
      "Completed  (round: 0, sync: 13/40 with L 50) sync_time: 0.03853s; inter_time: 0.001532s\n",
      "Completed  (round: 0, sync: 15/40 with L 50) sync_time: 0.03508s; inter_time: 0.001761s\n",
      "Completed  (round: 0, sync: 17/40 with L 50) sync_time: 0.03551s; inter_time: 0.002272s\n",
      "Completed  (round: 0, sync: 19/40 with L 50) sync_time: 0.03434s; inter_time: 0.002847s\n",
      "Completed  (round: 0, sync: 21/40 with L 50) sync_time: 0.03276s; inter_time: 0.001606s\n",
      "Completed  (round: 0, sync: 23/40 with L 50) sync_time: 0.03267s; inter_time: 0.001502s\n",
      "Completed  (round: 0, sync: 25/40 with L 50) sync_time: 0.03619s; inter_time: 0.0009038s\n",
      "Completed  (round: 0, sync: 27/40 with L 50) sync_time: 0.03287s; inter_time: 0.001164s\n",
      "Completed  (round: 0, sync: 29/40 with L 50) sync_time: 0.03315s; inter_time: 0.001476s\n",
      "Completed  (round: 0, sync: 31/40 with L 50) sync_time: 0.03306s; inter_time: 0.001066s\n",
      "Completed  (round: 0, sync: 33/40 with L 50) sync_time: 0.03358s; inter_time: 0.001351s\n",
      "Completed  (round: 0, sync: 35/40 with L 50) sync_time: 0.03417s; inter_time: 0.001217s\n",
      "Completed  (round: 0, sync: 37/40 with L 50) sync_time: 0.03971s; inter_time: 0.001302s\n",
      "Completed  (round: 0, sync: 39/40 with L 50) sync_time: 0.03947s; inter_time: 0.003669s\n",
      "Completed Pass 0 of data using L=50 and alpha=1. Stats: search+prune_time=0.6527s, inter_time=0.03314s, inter_count=143\n",
      "Completed  (round: 1, sync: 1/40 with L 50) sync_time: 0.04574s; inter_time: 0.02215s\n",
      "Completed  (round: 1, sync: 3/40 with L 50) sync_time: 0.06712s; inter_time: 0.01276s\n",
      "Completed  (round: 1, sync: 5/40 with L 50) sync_time: 0.06413s; inter_time: 0.01743s\n",
      "Completed  (round: 1, sync: 7/40 with L 50) sync_time: 0.06115s; inter_time: 0.02501s\n",
      "Completed  (round: 1, sync: 9/40 with L 50) sync_time: 0.05523s; inter_time: 0.03274s\n",
      "Completed  (round: 1, sync: 11/40 with L 50) sync_time: 0.05709s; inter_time: 0.04091s\n",
      "Completed  (round: 1, sync: 13/40 with L 50) sync_time: 0.05731s; inter_time: 0.04234s\n",
      "Completed  (round: 1, sync: 15/40 with L 50) sync_time: 0.06342s; inter_time: 0.05398s\n",
      "Completed  (round: 1, sync: 17/40 with L 50) sync_time: 0.06419s; inter_time: 0.05681s\n",
      "Completed  (round: 1, sync: 19/40 with L 50) sync_time: 0.05907s; inter_time: 0.0546s\n",
      "Completed  (round: 1, sync: 21/40 with L 50) sync_time: 0.05333s; inter_time: 0.05273s\n",
      "Completed  (round: 1, sync: 23/40 with L 50) sync_time: 0.06054s; inter_time: 0.05015s\n",
      "Completed  (round: 1, sync: 25/40 with L 50) sync_time: 0.06414s; inter_time: 0.05953s\n",
      "Completed  (round: 1, sync: 27/40 with L 50) sync_time: 0.05963s; inter_time: 0.06491s\n",
      "Completed  (round: 1, sync: 29/40 with L 50) sync_time: 0.05516s; inter_time: 0.07207s\n",
      "Completed  (round: 1, sync: 31/40 with L 50) sync_time: 0.06299s; inter_time: 0.08567s\n",
      "Completed  (round: 1, sync: 33/40 with L 50) sync_time: 0.06267s; inter_time: 0.0794s\n",
      "Completed  (round: 1, sync: 35/40 with L 50) sync_time: 0.06074s; inter_time: 0.09617s\n",
      "Completed  (round: 1, sync: 37/40 with L 50) sync_time: 0.06611s; inter_time: 0.09834s\n",
      "Completed  (round: 1, sync: 39/40 with L 50) sync_time: 0.06498s; inter_time: 0.08433s\n",
      "Completed Pass 1 of data using L=50 and alpha=1.2. Stats: search+prune_time=1.205s, inter_time=1.102s, inter_count=6058\n",
      "Starting final cleanup..done. Link time: 3.803s\n",
      "Degree: max:32  avg:32  min:32  count(deg<2):0\n",
      "Index built.\n",
      "Avg degree: 32\n",
      "Opened: /var/folders/hd/8ct1rg6n3w71kzr3lkhz1ffh0000gn/T/tmpnx6rqi70, size: 5120008, cache_size: 5120008\n",
      " Tellg: 1320016 as u64: 1320016\n",
      "Opened: ./DiskANN_data/siftsmall_mem.index, size: 1320016, cache_size: 1320016\n",
      "Opened: ./DiskANN_data/siftsmall_disk.index, cache_size: 67108864\n",
      "medoid: 3732B\n",
      "max_node_len: 644B\n",
      "nnodes_per_sector: 6B\n",
      "# sectors: 1667\n",
      "Sector #0written\n",
      "Output file written.\n",
      "Finished writing 6832128B\n",
      "Opened: /var/folders/hd/8ct1rg6n3w71kzr3lkhz1ffh0000gn/T/tmpnx6rqi70, size: 5120008, cache_size: 5120008\n",
      "Loading base /var/folders/hd/8ct1rg6n3w71kzr3lkhz1ffh0000gn/T/tmpnx6rqi70. #points: 10000. #dim: 128.\n",
      "Wrote 10000 points to sample file: ./DiskANN_data/siftsmall_sample_data.bin\n",
      "Indexing time: 5.366\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from diskann import IndexBuildParams, IndexSearchParams, DiskANN\n",
    "\n",
    "shared_lib_path = \"../../build/lib/pylib/libpydisk_index.dylib\"\n",
    "index_path = \"./DiskANN_data/siftsmall\"\n",
    "\n",
    "# np_vecs represents a numpy array containing input vectors\n",
    "diskAnn = DiskANN(shared_lib_path)\n",
    "idx_bld_params = IndexBuildParams(metric=\"l2\", \n",
    "                                  graph_degree=32, \n",
    "                                  search_list_size=50,\n",
    "                                  max_mem_build=1.0)\n",
    "\n",
    "diskAnn.build_disk_index(index_path, np_sift, idx_bld_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7331da6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading bin file /var/folders/hd/8ct1rg6n3w71kzr3lkhz1ffh0000gn/T/tmp69ckl4mh ...Metadata: #pts = 10000, #dims = 128, aligned_dim = 128...allocating aligned memory, 5120000 bytes...done. Copying data... done.\n",
      "********* Loaded query binary file...\n",
      "Using AVX2 functions for dist_cmp and dist_cmp_float\n",
      "Reading bin file ./DiskANN_data/siftsmall_pq_compressed.bin ...\n",
      "Metadata: #pts = 10000, #dims = 128...\n",
      "Reading bin file ./DiskANN_data/siftsmall_pq_pivots.bin ...\n",
      "Metadata: #pts = 256, #dims = 128...\n",
      " Stat(./DiskANN_data/siftsmall_pq_pivots.bin_chunk_offsets.bin) returned: 0\n",
      "Reading bin file ./DiskANN_data/siftsmall_pq_pivots.bin_rearrangement_perm.bin ...\n",
      "Metadata: #pts = 128, #dims = 1...\n",
      "Reading bin file ./DiskANN_data/siftsmall_pq_pivots.bin_chunk_offsets.bin ...\n",
      "Metadata: #pts = 129, #dims = 1...\n",
      "PQ data has 128 bytes per point.\n",
      "Reading bin file ./DiskANN_data/siftsmall_pq_pivots.bin_centroid.bin ...\n",
      "Metadata: #pts = 128, #dims = 1...\n",
      "PQ Pivots: #ctrs: 256, #dims: 128, #chunks: 128\n",
      "Loaded PQ centroids and in-memory compressed vectors. #points: 10000 #dim: 128 #aligned_dim: 128 #chunks: 128\n",
      " Stat(./DiskANN_data/siftsmall_disk.index_pq_pivots.bin) returned: -1\n",
      " Tellg: 6832128 as u64: 6832128\n",
      "Disk-Index File Meta-data: # nodes per sector: 6, max node len (bytes): 644, max node degree: 32\n",
      "Setting up thread-specific contexts for nthreads: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Opened file : ./DiskANN_data/siftsmall_disk.index\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Stat(./DiskANN_data/siftsmall_disk.index_medoids.bin) returned: -1\n",
      "Loading centroid data from medoids vector data of 1 medoid(s)\n",
      " Stat(./DiskANN_data/siftsmall_disk.index_max_base_norm.bin) returned: -1\n",
      "done..\n",
      "*********** Loaded Flash Index...\n",
      "Caching 100000 BFS nodes around medoid(s)\n",
      " Stat(./DiskANN_data/siftsmall_sample_data.bin) returned: 0\n",
      "Reading bin file ./DiskANN_data/siftsmall_sample_data.bin ...Metadata: #pts = 10000, #dims = 128, aligned_dim = 128...allocating aligned memory, 5120000 bytes...done. Copying data... done.\n",
      "Loading the cache list into memory....done.\n",
      "************ Loaded query cache from sample queries\n",
      "Done searching. Now saving results \n",
      "Writing bin: /tmp/query_res_60_idx_uint32.bin\n",
      "bin: #pts = 10000, #dims = 10, size = 400008B\n",
      "Finished writing bin.\n",
      "Writing bin: /tmp/query_res_60_dists_float.bin\n",
      "bin: #pts = 10000, #dims = 10, size = 400008B\n",
      "Finished writing bin.\n",
      "Clearing scratch\n"
     ]
    }
   ],
   "source": [
    "idx_srch_params = IndexSearchParams(num_nodes_to_cache=100000, \n",
    "                                    num_threads=32, \n",
    "                                    beam_width=4,\n",
    "                                    search_list_size=60)\n",
    "\n",
    "num_neighbours = 10\n",
    "\n",
    "query_res = diskAnn.search_disk_index(np_sift, num_neighbours, idx_srch_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e18d5df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unmatched vectors=0, recall=1.0\n"
     ]
    }
   ],
   "source": [
    "ctr = 0\n",
    "for i in range(len(np_sift)):\n",
    "    arr = query_res[i*num_neighbours:(i+1)*num_neighbours]\n",
    "    # Result is a tuple consisting of (id, dist)\n",
    "    arr = [a[0] for a in arr]\n",
    "    if i not in arr:\n",
    "        ctr += 1\n",
    "recall = 1 - ctr/len(np_sift)\n",
    "print(\"Number of unmatched vectors={}, recall={}\".format(ctr, recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9301af49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_dev",
   "language": "python",
   "name": "ml_dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
